{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histopathologic Cancer Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D,Flatten, BatchNormalization,Dropout,Reshape,Activation, GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D, AveragePooling2D, GlobalAveragePooling2D, Add\n",
    "from keras.models import Model\n",
    "from skimage.io import imread \n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter\n",
    "SAMPLE_COUNT = 20\n",
    "TRAINING_RATIO = 0.7\n",
    "IMAGE_SIZE = 96\n",
    "EPOCHS=10\n",
    "BATCH_SIZE =5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load Data\n",
    "input_dir = 'data/'\n",
    "training_dir = os.path.join(input_dir + 'train/')\n",
    "#training_dir = '/data/train'\n",
    "data_frame = pd.DataFrame({'path': glob(os.path.join(training_dir,'*.tif'))})\n",
    "#get id, data_frame.path is series\n",
    "data_frame['id'] = data_frame.path.map(lambda x: x.split('/')[1].split('\\\\')[1].split('.')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add trainingset label\n",
    "labels = pd.read_csv(input_dir + 'train_labels.csv')\n",
    "data_frame = data_frame.merge(labels, on='id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample\n",
    "negatives = data_frame[data_frame.label == 0].sample(SAMPLE_COUNT)\n",
    "positives = data_frame[data_frame.label == 1].sample(SAMPLE_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use reset_index() to get new sequential index\n",
    "data_frame = pd.concat([negatives,positives]).reset_index()\n",
    "data_frame = data_frame[['path','id','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame['image'] = data_frame['path'].map(imread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "training_path = 'data/training/'\n",
    "validation_path = 'data/validation/'\n",
    "\n",
    "for folder in [training_path, validation_path]:\n",
    "    for subfolder in ['0', '1']:\n",
    "        path = os.path.join(folder, subfolder)\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "training, validation = train_test_split(data_frame, train_size=0.7, stratify=data_frame['label'])\n",
    "\n",
    "data_frame.set_index('id', inplace=True)\n",
    "for images_and_path in [(training, training_path), (validation, validation_path)]:\n",
    "    images = images_and_path[0]\n",
    "    path = images_and_path[1]\n",
    "    for image in images['id'].values:\n",
    "        file_name = image + '.tif'\n",
    "        label = str(data_frame.loc[image,'label'])\n",
    "        destination = os.path.join(path, label, file_name)\n",
    "        if not os.path.exists(destination):\n",
    "            source = os.path.join(input_dir + 'train', file_name)\n",
    "            shutil.copyfile(source, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31d44a4b746c879c35da7bfa1e2ba05f88794976</th>\n",
       "      <td>data/train\\31d44a4b746c879c35da7bfa1e2ba05f887...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[252, 252, 252], [252, 252, 252], [252, 252,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57807e856a84c17ac886032ebac22f2499210039</th>\n",
       "      <td>data/train\\57807e856a84c17ac886032ebac22f24992...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[240, 235, 239], [239, 234, 238], [239, 234,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5cdb808784c230a31ac3a84006b5d34e36728363</th>\n",
       "      <td>data/train\\5cdb808784c230a31ac3a84006b5d34e367...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[164, 119, 148], [163, 122, 154], [36, 0, 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90a56681dfa6d7b689856dc40ce9dd76e67bdbd7</th>\n",
       "      <td>data/train\\90a56681dfa6d7b689856dc40ce9dd76e67...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[233, 238, 232], [233, 233, 233], [241, 230,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06528e66d433eadb384204100c0c79a1dbbb8e20</th>\n",
       "      <td>data/train\\06528e66d433eadb384204100c0c79a1dbb...</td>\n",
       "      <td>0</td>\n",
       "      <td>[[[246, 245, 243], [246, 245, 243], [245, 244,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       path  \\\n",
       "id                                                                                            \n",
       "31d44a4b746c879c35da7bfa1e2ba05f88794976  data/train\\31d44a4b746c879c35da7bfa1e2ba05f887...   \n",
       "57807e856a84c17ac886032ebac22f2499210039  data/train\\57807e856a84c17ac886032ebac22f24992...   \n",
       "5cdb808784c230a31ac3a84006b5d34e36728363  data/train\\5cdb808784c230a31ac3a84006b5d34e367...   \n",
       "90a56681dfa6d7b689856dc40ce9dd76e67bdbd7  data/train\\90a56681dfa6d7b689856dc40ce9dd76e67...   \n",
       "06528e66d433eadb384204100c0c79a1dbbb8e20  data/train\\06528e66d433eadb384204100c0c79a1dbb...   \n",
       "\n",
       "                                          label  \\\n",
       "id                                                \n",
       "31d44a4b746c879c35da7bfa1e2ba05f88794976      0   \n",
       "57807e856a84c17ac886032ebac22f2499210039      0   \n",
       "5cdb808784c230a31ac3a84006b5d34e36728363      0   \n",
       "90a56681dfa6d7b689856dc40ce9dd76e67bdbd7      0   \n",
       "06528e66d433eadb384204100c0c79a1dbbb8e20      0   \n",
       "\n",
       "                                                                                      image  \n",
       "id                                                                                           \n",
       "31d44a4b746c879c35da7bfa1e2ba05f88794976  [[[252, 252, 252], [252, 252, 252], [252, 252,...  \n",
       "57807e856a84c17ac886032ebac22f2499210039  [[[240, 235, 239], [239, 234, 238], [239, 234,...  \n",
       "5cdb808784c230a31ac3a84006b5d34e36728363  [[[164, 119, 148], [163, 122, 154], [36, 0, 38...  \n",
       "90a56681dfa6d7b689856dc40ce9dd76e67bdbd7  [[[233, 238, 232], [233, 233, 233], [241, 230,...  \n",
       "06528e66d433eadb384204100c0c79a1dbbb8e20  [[[246, 245, 243], [246, 245, 243], [245, 244,...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(glob(os.path.join(training_dir,'*.tif')))\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation\n",
    "training_data_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             rotation_range=180,\n",
    "                                             zoom_range=0.4,\n",
    "                                             width_shift_range=0.3,\n",
    "                                             height_shift_range=0.3,\n",
    "                                             shear_range=0.3,\n",
    "                                             channel_shift_range=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84 images belonging to 2 classes.\n",
      "Found 36 images belonging to 2 classes.\n",
      "Found 36 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_generator = training_data_generator.flow_from_directory(training_path,\n",
    "                                                                target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                batch_size = BATCH_SIZE,\n",
    "                                                                class_mode='binary')\n",
    "\n",
    "validation_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
    "                                                                              target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                              batch_size=BATCH_SIZE,\n",
    "                                                                              class_mode='binary')\n",
    "\n",
    "testing_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
    "                                                                           target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                                                           batch_size=BATCH_SIZE,\n",
    "                                                                           class_mode='binary',\n",
    "                                                                           shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module of structure of neural network (Resnet 50)\n",
    "def Conv2d_BN(Input, n_filter, kernel_size, strides=(1,1),padding='same', stage, block, n_serial):\n",
    "    #stage: integer, current stage label, used for generating layer names\n",
    "    #block: 'a','b'....,current block label, used for generating layer names\n",
    "    #n_serial: used for generating layer names\n",
    "    conv_name_base = 'res' + str(stage)+ block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block +  '_branch'\n",
    "    x = Conv2D(n_filter, kernel_size, padding=padding,strides=strides,activation='relu', name=conv_name_base+n_serial)(Input)\n",
    "    x = BatchNormalization(name=bn_name_base+n_serial )(x)\n",
    "    return x\n",
    "\n",
    "def identity_Block(Input, n_filters, kernel_size, strides=(1,1), stage, block, with_conv_shortcut=False):\n",
    "    #kernel_size: default=3\n",
    "    filter1, filter2, filter3 = filters\n",
    "    x = Conv2d_BN(Input,n_filter=filter1, kernel_size=1, stage, block, n_serial='2a')\n",
    "    x = Conv2d_BN(x,n_filter=filter2, kernel_size=kernel_size, stage, block, n_serial='2b')\n",
    "    x = Conv2d_BN(x,n_filter=filter3, kernel_size=1, stage, block, n_serial='2b')\n",
    "    \n",
    "    if with_conv_shortcut:\n",
    "        shortcut = Conv2d_BN(Input, n_filter=filter3, kernel_size=1, )\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "def model_cnn():\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
